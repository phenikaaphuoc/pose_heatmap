{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from argparse import ArgumentParser\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import mmcv\n",
    "import mmengine\n",
    "import numpy as np\n",
    "import decord\n",
    "\n",
    "from mmpose.apis import inference_topdown\n",
    "from mmpose.apis import init_model as init_pose_estimator\n",
    "from mmpose.evaluation.functional import nms\n",
    "from mmpose.structures import merge_data_samples\n",
    "from mmpose.utils import adapt_mmdet_pipeline\n",
    "\n",
    "try:\n",
    "    from mmdet.apis import inference_detector, init_detector\n",
    "    has_mmdet = True\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    has_mmdet = False\n",
    "\n",
    "\n",
    "def process_one_image(args,\n",
    "                      img,\n",
    "                      detector,\n",
    "                      pose_estimator,\n",
    "                      show_interval=0):\n",
    "    \"\"\"Visualize predicted keypoints (and heatmaps) of one image.\"\"\"\n",
    "\n",
    "    # predict bbox\n",
    "    det_result = inference_detector(detector, img)\n",
    "    pred_instance = det_result.pred_instances.cpu().numpy()\n",
    "    bboxes = np.concatenate(\n",
    "        (pred_instance.bboxes, pred_instance.scores[:, None]), axis=1)\n",
    "    bboxes = bboxes[np.logical_and(pred_instance.labels == args.det_cat_id,\n",
    "                                   pred_instance.scores > args.bbox_thr)]\n",
    "    bboxes = bboxes[nms(bboxes, args.nms_thr), :4]\n",
    "    #bboxes numppy array [[x1y1,x2,y2],[...]]\n",
    "    \n",
    "    pose_results = inference_topdown(pose_estimator, img, bboxes)\n",
    "    data_samples = merge_data_samples(pose_results)\n",
    "    return data_samples.get('pred_instances', None)\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--det_config',default=r\"D:\\pyskl\\mmdetection\\configs\\faster_rcnn\\faster-rcnn_r50-caffe_fpn_ms-1x_coco-person.py\",help='Config file for detection')\n",
    "    parser.add_argument('--det_checkpoint',default=r\"C:\\Users\\phuoc\\Downloads\\faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\", help='Checkpoint file for detection')\n",
    "    parser.add_argument('--pose_config',default=r\"D:\\pyskl\\td-hm_hrnet-w48_8xb32-210e_coco-256x192.py\", help='Config file for pose')\n",
    "    parser.add_argument('--pose_checkpoint',default=r\"D:\\pyskl\\td-hm_hrnet-w48_8xb32-210e_coco-256x192-0e67c616_20220913.pth\", help='Checkpoint file for pose')\n",
    "    parser.add_argument(\n",
    "        '--input', type=str, default=r\"webcam\", help='Image/Video file')\n",
    "    parser.add_argument(\n",
    "        '--device', default='cpu', help='Device used for inference')\n",
    "    parser.add_argument(\n",
    "        '--bbox-thr',\n",
    "        type=float,\n",
    "        default=0.3,\n",
    "        help='Bounding box score threshold')\n",
    "    parser.add_argument(\n",
    "        '--nms-thr',\n",
    "        type=float,\n",
    "        default=0.3,\n",
    "        help='IoU threshold for bounding box NMS')\n",
    "    parser.add_argument(\n",
    "        '--kpt-thr',\n",
    "        type=float,\n",
    "        default=0.3,\n",
    "        help='Visualizing keypoint thresholds')\n",
    "    parser.add_argument(\n",
    "        '--draw-heatmap',\n",
    "        action='store_true',\n",
    "        default=True,\n",
    "        help='Draw heatmap predicted by the model')\n",
    "    parser.add_argument(\n",
    "        '--show-kpt-idx',\n",
    "        action='store_true',\n",
    "        default=False,\n",
    "        help='Whether to show the index of keypoints')\n",
    "    parser.add_argument(\n",
    "        '--skeleton-style',\n",
    "        default='mmpose',\n",
    "        type=str,\n",
    "        choices=['mmpose', 'openpose'],\n",
    "        help='Skeleton style selection')\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    detector = init_detector(\n",
    "        args.det_config, args.det_checkpoint, device=args.device)\n",
    "    detector.cfg = adapt_mmdet_pipeline(detector.cfg)\n",
    "\n",
    "    pose_estimator = init_pose_estimator(\n",
    "        args.pose_config,\n",
    "        args.pose_checkpoint,\n",
    "        device=args.device,\n",
    "        cfg_options=dict(\n",
    "            model=dict(test_cfg=dict(output_heatmaps=args.draw_heatmap))))\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    if True:\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            # topdown pose estimation\n",
    "            pred_instances = process_one_image(args, frame, detector,\n",
    "                                               pose_estimator,\n",
    "                                               0.001)\n",
    "\n",
    "        \n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                    break\n",
    "\n",
    "        cap.release()\n",
    "def extract_frame(video_path):\n",
    "    vid = decord.VideoReader(video_path)\n",
    "    return [x.asnumpy() for x in vid]\n",
    "\n",
    "\n",
    "def detection_inference(model, frames):\n",
    "    results = []\n",
    "    for frame in frames:\n",
    "        result = inference_detector(model, frame)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from argparse import ArgumentParser\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import mmcv\n",
    "import mmengine\n",
    "import numpy as np\n",
    "import decord\n",
    "\n",
    "from mmpose.apis import inference_topdown\n",
    "from mmpose.apis import init_model as init_pose_estimator\n",
    "from mmpose.evaluation.functional import nms\n",
    "from mmpose.structures import merge_data_samples\n",
    "from mmpose.utils import adapt_mmdet_pipeline\n",
    "\n",
    "try:\n",
    "    from mmdet.apis import inference_detector, init_detector\n",
    "    has_mmdet = True\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    has_mmdet = False\n",
    "\n",
    "\n",
    "def process_one_image(img,detector,pose_estimator,show_interval=0):\n",
    "    \"\"\"Visualize predicted keypoints (and heatmaps) of one image.\"\"\"\n",
    "\n",
    "    # predict bbox\n",
    "    det_result = inference_detector(detector, img)\n",
    "    pred_instance = det_result.pred_instances.cpu().numpy()\n",
    "    bboxes = np.concatenate(\n",
    "        (pred_instance.bboxes, pred_instance.scores[:, None]), axis=1)\n",
    "    bboxes = bboxes[np.logical_and(pred_instance.labels == args.det_cat_id,\n",
    "                                   pred_instance.scores > args.bbox_thr)]\n",
    "    bboxes = bboxes[nms(bboxes, args.nms_thr), :4]\n",
    "    #bboxes numppy array [[x1y1,x2,y2],[...]]\n",
    "    \n",
    "    pose_results = inference_topdown(pose_estimator, img, bboxes)\n",
    "    data_samples = merge_data_samples(pose_results)\n",
    "    return data_samples.get('pred_instances', None)\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--det_config',default=r\"D:\\pyskl\\mmdetection\\configs\\faster_rcnn\\faster-rcnn_r50-caffe_fpn_ms-1x_coco-person.py\",help='Config file for detection')\n",
    "    parser.add_argument('--det_checkpoint',default=r\"C:\\Users\\phuoc\\Downloads\\faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\", help='Checkpoint file for detection')\n",
    "    parser.add_argument('--pose_config',default=r\"D:\\pyskl\\td-hm_hrnet-w48_8xb32-210e_coco-256x192.py\", help='Config file for pose')\n",
    "    parser.add_argument('--pose_checkpoint',default=r\"D:\\pyskl\\td-hm_hrnet-w48_8xb32-210e_coco-256x192-0e67c616_20220913.pth\", help='Checkpoint file for pose')\n",
    "    parser.add_argument(\n",
    "        '--input', type=str, default=r\"webcam\", help='Image/Video file')\n",
    "    parser.add_argument(\n",
    "        '--device', default='cpu', help='Device used for inference')\n",
    "    parser.add_argument(\n",
    "        '--bbox-thr',\n",
    "        type=float,\n",
    "        default=0.3,\n",
    "        help='Bounding box score threshold')\n",
    "    parser.add_argument(\n",
    "        '--nms-thr',\n",
    "        type=float,\n",
    "        default=0.3,\n",
    "        help='IoU threshold for bounding box NMS')\n",
    "    parser.add_argument(\n",
    "        '--kpt-thr',\n",
    "        type=float,\n",
    "        default=0.3,\n",
    "        help='Visualizing keypoint thresholds')\n",
    "    parser.add_argument(\n",
    "        '--draw-heatmap',\n",
    "        action='store_true',\n",
    "        default=True,\n",
    "        help='Draw heatmap predicted by the model')\n",
    "    parser.add_argument(\n",
    "        '--show-kpt-idx',\n",
    "        action='store_true',\n",
    "        default=False,\n",
    "        help='Whether to show the index of keypoints')\n",
    "    parser.add_argument(\n",
    "        '--skeleton-style',\n",
    "        default='mmpose',\n",
    "        type=str,\n",
    "        choices=['mmpose', 'openpose'],\n",
    "        help='Skeleton style selection')\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    detector = init_detector(\n",
    "        args.det_config, args.det_checkpoint, device=args.device)\n",
    "    detector.cfg = adapt_mmdet_pipeline(detector.cfg)\n",
    "\n",
    "    pose_estimator = init_pose_estimator(\n",
    "        args.pose_config,\n",
    "        args.pose_checkpoint,\n",
    "        device=args.device,\n",
    "        cfg_options=dict(\n",
    "            model=dict(test_cfg=dict(output_heatmaps=args.draw_heatmap))))\n",
    "\n",
    "def extract_frame(video_path):\n",
    "    vid = decord.VideoReader(video_path)\n",
    "    return [x.asnumpy() for x in vid]\n",
    "\n",
    "\n",
    "def detection_inference(model, frames):\n",
    "    results = []\n",
    "    for frame in frames:\n",
    "        result = inference_detector(model, frame)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose_estimate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
